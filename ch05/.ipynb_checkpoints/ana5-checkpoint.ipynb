{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n",
      "200 1.1 110.00000000000001 2.2\n"
     ]
    }
   ],
   "source": [
    "import layer_naive\n",
    "apple = 100\n",
    "num_apple = 2\n",
    "tax = 1.1\n",
    "\n",
    "# layer\n",
    "mul_apple_layer = layer_naive.MulLayer()\n",
    "mul_tax_layer = layer_naive.MulLayer()\n",
    "\n",
    "# forward\n",
    "price_apple = mul_apple_layer.forward(apple, num_apple)\n",
    "price = mul_tax_layer.forward(price_apple, tax)\n",
    "print(price)\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "print(dtax, dapple_price, dapple_num, dapple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "1.1 1.1 2.2 110.00000000000001 3.3000000000000003 165.0\n"
     ]
    }
   ],
   "source": [
    "import layer_naive\n",
    "import importlib\n",
    "importlib.reload(layer_naive)\n",
    "\n",
    "apple = 100\n",
    "num_apple = 2\n",
    "orange = 150\n",
    "num_orange = 3\n",
    "tax = 1.1\n",
    "\n",
    "# layer\n",
    "mul_apple_layer = layer_naive.MulLayer()\n",
    "mul_orange_layer = layer_naive.MulLayer()\n",
    "add_layer = layer_naive.AddLayer()\n",
    "mul_tax_layer = layer_naive.MulLayer()\n",
    "\n",
    "# forward \n",
    "price_apple = mul_apple_layer.forward(apple, num_apple)\n",
    "price_orange = mul_orange_layer.forward(orange, num_orange)\n",
    "price_sum = add_layer.forward(price_apple, price_orange)\n",
    "price = mul_tax_layer.forward(price_sum, tax)\n",
    "print(price)\n",
    "\n",
    "#backward\n",
    "dprice = 1\n",
    "dprice_sum, dtax = mul_tax_layer.backward(dprice)\n",
    "dprice_apple, dprice_orange = add_layer.backward(dprice_sum)\n",
    "dapple, dnum_apple = mul_apple_layer.backward(dprice_apple)\n",
    "dorange, dnum_orange = mul_orange_layer.backward(dprice_orange)\n",
    "print(dprice_apple, dprice_orange, dapple, dnum_apple, dorange, dnum_orange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "np.where(a>5, a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0864166666667 0.0865\n",
      "0.9041 0.9093\n",
      "0.9239 0.9264\n",
      "0.933916666667 0.9302\n",
      "0.9434 0.9427\n",
      "0.95025 0.9505\n",
      "0.956483333333 0.9548\n",
      "0.96095 0.9576\n",
      "0.96465 0.9615\n",
      "0.96635 0.9626\n",
      "0.967716666667 0.963\n",
      "0.970883333333 0.9644\n",
      "0.9722 0.9654\n",
      "0.974733333333 0.9672\n",
      "0.974883333333 0.9675\n",
      "0.9761 0.9674\n",
      "0.977833333333 0.969\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "from twolayers import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) =\\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(x_train.shape[1], 50, t_train.shape[1])\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "n_epoch = max(int(train_size / batch_size), 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i % n_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1452 0.1499\n",
      "0.903716666667 0.9082\n",
      "0.925166666667 0.929\n",
      "0.933733333333 0.9343\n",
      "0.944816666667 0.9451\n",
      "0.950933333333 0.95\n",
      "0.953416666667 0.9511\n",
      "0.959533333333 0.9567\n",
      "0.9629 0.9581\n",
      "0.965283333333 0.9605\n",
      "0.9662 0.9628\n",
      "0.970333333333 0.9648\n",
      "0.9711 0.9666\n",
      "0.974516666667 0.9682\n",
      "0.975966666667 0.97\n",
      "0.9775 0.9699\n",
      "0.978833333333 0.9712\n"
     ]
    }
   ],
   "source": [
    "import common.optimizer as opt\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) =\\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(x_train.shape[1], 50, t_train.shape[1])\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "n_epoch = max(int(train_size / batch_size), 1)\n",
    "\n",
    "optimizer = opt.SGD(learning_rate)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "\n",
    "    # for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "    #    network.params[key] -= learning_rate * grad[key]\n",
    "    optimizer.update(network.params, grads)\n",
    "\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i % n_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,2) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3d6fc90125fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,2) (3,) "
     ]
    }
   ],
   "source": [
    "a = np.arange(6).reshape(3,2)\n",
    "a/np.sum(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [2 2 2]\n",
      " [4 4 4]]\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n"
     ]
    }
   ],
   "source": [
    "print(a[:, (0, 0, 0)])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
