{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    return 0.01 * x**2 + 0.1 * x\n",
    "\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x + h) - f(x - h)) / (2*h)\n",
    "\n",
    "def diff_tangent(f, x0):\n",
    "    alpha = numerical_diff(f, x0)\n",
    "    return lambda x: alpha * (x - x0) + f(x0)\n",
    "\n",
    "%matplotlib inline\n",
    "x = np.arange(0., 100., 0.1)\n",
    "y = f1(x)\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, diff_tangent(f1, 50)(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for i in range(x.size):\n",
    "        hs = np.zeros_like(x)\n",
    "        hs[i] = h\n",
    "        grad[i] = (f(x + hs) - f(x - hs)) / (2 * h)\n",
    "    return grad\n",
    "\n",
    "def f2(x):\n",
    "    return sum(x**2)\n",
    "\n",
    "numerical_gradient(f2, np.array([0., 2.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "    return x\n",
    "\n",
    "init_x = np.array([3., 4.])\n",
    "gradient_descent(f2, init_x, 0.1, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_gradient_descent(f, init_x, lr=0.01, step_num=100, step_plot=10):\n",
    "    x = init_x\n",
    "    xs = [x.copy()]\n",
    "    for _ in range(int(step_num/step_plot)):\n",
    "        x = gradient_descent(f, x, lr=lr, step_num=step_plot)\n",
    "        xs.append(x.copy())\n",
    "    xs = np.array(xs)\n",
    "    plt.plot(xs[:, 0], xs[:, 1], 'ro', ms=6)\n",
    "    plt.show()\n",
    "\n",
    "%matplotlib inline\n",
    "init_x = np.array([3., 4.])\n",
    "plot_gradient_descent(f2, init_x, 0.1, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(gradient_simplenet)\n",
    "#import gradient_simplenet\n",
    "\n",
    "net = gradient_simplenet.simpleNet()\n",
    "print(net.W)\n",
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)\n",
    "print(np.argmax(p))\n",
    "label = np.array([0, 0, 1])\n",
    "net.loss(x, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from common import gradient\n",
    "import importlib\n",
    "importlib.reload(gradient)\n",
    "\n",
    "def f(W):\n",
    "    net.W = W\n",
    "    return net.loss(x, label)\n",
    "\n",
    "dW = gradient.numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import two_layers_net\n",
    "importlib.reload(two_layers_net)\n",
    "net = two_layers_net.TwoLayersNet(3, 5, 2)\n",
    "\n",
    "x = np.array([1, 2, 3])\n",
    "label = np.array([1, 1])\n",
    "net.numerical_gradient(x, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import two_layers_net\n",
    "import importlib\n",
    "importlib.reload(two_layers_net)\n",
    "net = two_layers_net.TwoLayersNet(784, 100, 10)\n",
    "print(net.params['W1'].shape)\n",
    "print(net.params['b1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "y = np.random.rand(100, 10)\n",
    "net.loss(x, y)\n",
    "grads = net.numerical_gradient(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch:: acc_train: 0.09035,  acc_test: 0.0892\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layers_net import TwoLayersNet\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) =\\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "iter_num = 10000\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "net = TwoLayersNet(784, 50, 10)\n",
    "\n",
    "losses_train = []\n",
    "acc_trains, acc_tests = [], []\n",
    "iter_per_epoch = int(x_train.shape[0]/batch_size)\n",
    "n = 1\n",
    "for i in range(iter_num):\n",
    "    batch_mask = np.random.choice(x_train.shape[0], batch_size)\n",
    "    x_batch, y_batch = x_train[batch_mask], y_train[batch_mask]\n",
    "\n",
    "    grads = net.numerical_gradient(x_batch, y_batch)\n",
    "    for k in net.params.keys():\n",
    "        net.params[k] -= learning_rate * grads[k]\n",
    "\n",
    "    losses_train.append(net.loss(x_batch, y_batch))\n",
    "    if i % iter_per_epoch == 0:\n",
    "        acc_trains.append(net.accuracy(x_train, y_train))\n",
    "        acc_tests.append(net.accuracy(x_test, y_test))\n",
    "        print('%d epoch:: acc_train: %s,  acc_test: %s' % (n, acc_trains[-1], acc_tests[-1]))\n",
    "        n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(losses_train)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
